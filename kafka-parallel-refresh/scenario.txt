Replicated table: CDCDEMO.TAB_BIG (100M rows)
Table structure and sample data in database-oracle.sql

Subscription BIGTAB1 (Oracle to Kafka)

Kafka properties (00-sub-config.png)
    ZooKeeper mode, kafko:2181
    Schema registy kafko:8081
    Topic prefix and commit stream options are not configured

User exit properties (01-user-exit.png)
    com.datamirror.ts.target.publication.userexit.sample.kafka.KcopMultiRowAvroLiveAuditIntegrated
    -file:/home/cdcuser/kafka-avro-config.properties

$ cat kafka-avro-config.properties 
schema.registry.url=http://kafko:8081
audit.jcfs=ENTTYP,CCID
before.update.record.mode=ALWAYS
default.null.JCF.value=""
null.UB.ENTTYP.override="UB"

Steps:


1. Copy the BIGTAB1 subscription in MC, creating the REFBIG01 subscription
(screens 10 to 15)


2. Set the subscription prefix to get the same target queue.

Topic name example: kafka1.ora1.sourcedb.cdcdemo.tab0
Topic name format: "<CDC instance>.<SUB name lowercase>.sourcedb.<schema>.<table>"
Topic name format with prefix: "<Prefix value>.<schema>.<table>"

So, we need to set the prefix to "<CDC instance>.<Sub name lowercase>.sourcedb",
which is "kafka1.ora1.sourcedb" (screen 21)


3. Prepare the CHCCLP script to duplicate and adjust the REFBIG01 N-1 times
(see example in prepare-refresh-subs.chcclp).
We will use the Refresh filter to split the full set of records into the partitions.


4. Run the CHCCLP script through "chcclp -f scriptFile".
Ensure that there are no errors.
Worth to debug the script first on a single copy of subscription.


5. Check the properties of the newly created subscriptions (screen 22).


6. Prepare the CHCCLP script to:
(a) mark the table capture point for the BIGTAB1 subscription
(b) start the refresh for all the remaining subscriptions


7. Start the workload simulation script, so that we have changes
over our large table.


8. Start the refresh using this script.
Validate that the data goes to the single expected topic,
in our case being "kafka1.bigtab1.sourcedb.cdcdemo.tab_big"

kafka-topics.sh --list --zookeeper localhost:2181
kafka-topics.sh --list --zookeeper localhost:2181 | grep -vE '[-]commitstream$'


9. Monitor the refresh progress.
It is possible to automate catching the end of refresh through CHCCLP's 
"monitor replication" command.


10. After the Refresh is complete, start the original subscription
for mirroring.

Ensure that the changes still go to the expected target topic.

kafka-topics.sh --list --zookeeper localhost:2181 | grep -vE '[-]commitstream$'


11. Final cleanup

./kafka/bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics \
  --entity-name kafka1.bigtab1.sourcedb.cdcdemo.tab_big \
  --describe

./kafka/bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics \
  --entity-name kafka1.bigtab1.sourcedb.cdcdemo.tab_big \
  --alter --add-config retention.ms=1000

<wait for some time, 1+ minute>

./kafka/bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics \
  --entity-name kafka1.bigtab1.sourcedb.cdcdemo.tab_big \
  --alter --delete-config retention.ms
